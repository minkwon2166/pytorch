{
  "query_sha=https://api.github.com/repos/pytorch/pytorch/compare/master...030a6d3fe98e46c82cdbae9b93a72ceab4febfd6 None None": {
    "url": "https://api.github.com/repos/pytorch/pytorch/compare/master...030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
    "html_url": "https://github.com/pytorch/pytorch/compare/master...030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
    "permalink_url": "https://github.com/pytorch/pytorch/compare/pytorch:f2f42e5...pytorch:030a6d3",
    "diff_url": "https://github.com/pytorch/pytorch/compare/master...030a6d3fe98e46c82cdbae9b93a72ceab4febfd6.diff",
    "patch_url": "https://github.com/pytorch/pytorch/compare/master...030a6d3fe98e46c82cdbae9b93a72ceab4febfd6.patch",
    "base_commit": {
      "sha": "f2f42e54ca67c5bcec07bc2e1c75b07f5d23f65b",
      "node_id": "C_kwDOA-j9z9oAKGYyZjQyZTU0Y2E2N2M1YmNlYzA3YmMyZTFjNzViMDdmNWQyM2Y2NWI",
      "commit": {
        "author": {
          "name": "Aaron Gokaslan",
          "email": "aaronGokaslan@gmail.com",
          "date": "2023-01-25T21:06:48Z"
        },
        "committer": {
          "name": "PyTorch MergeBot",
          "email": "pytorchmergebot@users.noreply.github.com",
          "date": "2023-01-25T21:06:51Z"
        },
        "message": "Apply some std::move and param value fixups to aten (#92901)\n\nI noticed a few perf issues in the latest ATen and decided to fixup a few other miscellaneous ones I noticed recently.\nPull Request resolved: https://github.com/pytorch/pytorch/pull/92901\nApproved by: https://github.com/ezyang",
        "tree": {
          "sha": "69d2f51fec0e543f17f25caf7bf34a10b6a717d1",
          "url": "https://api.github.com/repos/pytorch/pytorch/git/trees/69d2f51fec0e543f17f25caf7bf34a10b6a717d1"
        },
        "url": "https://api.github.com/repos/pytorch/pytorch/git/commits/f2f42e54ca67c5bcec07bc2e1c75b07f5d23f65b",
        "comment_count": 0,
        "verification": {
          "verified": false,
          "reason": "unsigned",
          "signature": null,
          "payload": null
        }
      },
      "url": "https://api.github.com/repos/pytorch/pytorch/commits/f2f42e54ca67c5bcec07bc2e1c75b07f5d23f65b",
      "html_url": "https://github.com/pytorch/pytorch/commit/f2f42e54ca67c5bcec07bc2e1c75b07f5d23f65b",
      "comments_url": "https://api.github.com/repos/pytorch/pytorch/commits/f2f42e54ca67c5bcec07bc2e1c75b07f5d23f65b/comments",
      "author": {
        "login": "Skylion007",
        "id": 2053727,
        "node_id": "MDQ6VXNlcjIwNTM3Mjc=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2053727?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/Skylion007",
        "html_url": "https://github.com/Skylion007",
        "followers_url": "https://api.github.com/users/Skylion007/followers",
        "following_url": "https://api.github.com/users/Skylion007/following{/other_user}",
        "gists_url": "https://api.github.com/users/Skylion007/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/Skylion007/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/Skylion007/subscriptions",
        "organizations_url": "https://api.github.com/users/Skylion007/orgs",
        "repos_url": "https://api.github.com/users/Skylion007/repos",
        "events_url": "https://api.github.com/users/Skylion007/events{/privacy}",
        "received_events_url": "https://api.github.com/users/Skylion007/received_events",
        "type": "User",
        "site_admin": false
      },
      "committer": {
        "login": "pytorchmergebot",
        "id": 97764156,
        "node_id": "U_kgDOBdPDPA",
        "avatar_url": "https://avatars.githubusercontent.com/u/97764156?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pytorchmergebot",
        "html_url": "https://github.com/pytorchmergebot",
        "followers_url": "https://api.github.com/users/pytorchmergebot/followers",
        "following_url": "https://api.github.com/users/pytorchmergebot/following{/other_user}",
        "gists_url": "https://api.github.com/users/pytorchmergebot/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/pytorchmergebot/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/pytorchmergebot/subscriptions",
        "organizations_url": "https://api.github.com/users/pytorchmergebot/orgs",
        "repos_url": "https://api.github.com/users/pytorchmergebot/repos",
        "events_url": "https://api.github.com/users/pytorchmergebot/events{/privacy}",
        "received_events_url": "https://api.github.com/users/pytorchmergebot/received_events",
        "type": "User",
        "site_admin": false
      },
      "parents": [
        {
          "sha": "b073c09f7a1e039046fe9e5842d287b27520fbd9",
          "url": "https://api.github.com/repos/pytorch/pytorch/commits/b073c09f7a1e039046fe9e5842d287b27520fbd9",
          "html_url": "https://github.com/pytorch/pytorch/commit/b073c09f7a1e039046fe9e5842d287b27520fbd9"
        }
      ]
    },
    "merge_base_commit": {
      "sha": "8972a9fe6aa8be8f8035c83094ed371973bfbe73",
      "node_id": "C_kwDOA-j9z9oAKDg5NzJhOWZlNmFhOGJlOGY4MDM1YzgzMDk0ZWQzNzE5NzNiZmJlNzM",
      "commit": {
        "author": {
          "name": "Jane Xu",
          "email": "janeyx@fb.com",
          "date": "2023-01-20T21:52:07Z"
        },
        "committer": {
          "name": "PyTorch MergeBot",
          "email": "pytorchmergebot@users.noreply.github.com",
          "date": "2023-01-21T02:40:18Z"
        },
        "message": "[BE][CI] rename .jenkins to .ci, add symlink (#92621)\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/92621\nApproved by: https://github.com/huydhn, https://github.com/ZainRizvi",
        "tree": {
          "sha": "77617654d89b4690c19c1b9a5fe298aa47cb0386",
          "url": "https://api.github.com/repos/pytorch/pytorch/git/trees/77617654d89b4690c19c1b9a5fe298aa47cb0386"
        },
        "url": "https://api.github.com/repos/pytorch/pytorch/git/commits/8972a9fe6aa8be8f8035c83094ed371973bfbe73",
        "comment_count": 1,
        "verification": {
          "verified": false,
          "reason": "unsigned",
          "signature": null,
          "payload": null
        }
      },
      "url": "https://api.github.com/repos/pytorch/pytorch/commits/8972a9fe6aa8be8f8035c83094ed371973bfbe73",
      "html_url": "https://github.com/pytorch/pytorch/commit/8972a9fe6aa8be8f8035c83094ed371973bfbe73",
      "comments_url": "https://api.github.com/repos/pytorch/pytorch/commits/8972a9fe6aa8be8f8035c83094ed371973bfbe73/comments",
      "author": {
        "login": "janeyx99",
        "id": 31798555,
        "node_id": "MDQ6VXNlcjMxNzk4NTU1",
        "avatar_url": "https://avatars.githubusercontent.com/u/31798555?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/janeyx99",
        "html_url": "https://github.com/janeyx99",
        "followers_url": "https://api.github.com/users/janeyx99/followers",
        "following_url": "https://api.github.com/users/janeyx99/following{/other_user}",
        "gists_url": "https://api.github.com/users/janeyx99/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/janeyx99/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/janeyx99/subscriptions",
        "organizations_url": "https://api.github.com/users/janeyx99/orgs",
        "repos_url": "https://api.github.com/users/janeyx99/repos",
        "events_url": "https://api.github.com/users/janeyx99/events{/privacy}",
        "received_events_url": "https://api.github.com/users/janeyx99/received_events",
        "type": "User",
        "site_admin": false
      },
      "committer": {
        "login": "pytorchmergebot",
        "id": 97764156,
        "node_id": "U_kgDOBdPDPA",
        "avatar_url": "https://avatars.githubusercontent.com/u/97764156?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/pytorchmergebot",
        "html_url": "https://github.com/pytorchmergebot",
        "followers_url": "https://api.github.com/users/pytorchmergebot/followers",
        "following_url": "https://api.github.com/users/pytorchmergebot/following{/other_user}",
        "gists_url": "https://api.github.com/users/pytorchmergebot/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/pytorchmergebot/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/pytorchmergebot/subscriptions",
        "organizations_url": "https://api.github.com/users/pytorchmergebot/orgs",
        "repos_url": "https://api.github.com/users/pytorchmergebot/repos",
        "events_url": "https://api.github.com/users/pytorchmergebot/events{/privacy}",
        "received_events_url": "https://api.github.com/users/pytorchmergebot/received_events",
        "type": "User",
        "site_admin": false
      },
      "parents": [
        {
          "sha": "09eb4c2a70e3b933a4bd6ff99619f5d9aee8fd6b",
          "url": "https://api.github.com/repos/pytorch/pytorch/commits/09eb4c2a70e3b933a4bd6ff99619f5d9aee8fd6b",
          "html_url": "https://github.com/pytorch/pytorch/commit/09eb4c2a70e3b933a4bd6ff99619f5d9aee8fd6b"
        }
      ]
    },
    "status": "diverged",
    "ahead_by": 1,
    "behind_by": 155,
    "total_commits": 1,
    "commits": [
      {
        "sha": "030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
        "node_id": "C_kwDOA-j9z9oAKDAzMGE2ZDNmZTk4ZTQ2YzgyY2RiYWU5YjkzYTcyY2VhYjRmZWJmZDY",
        "commit": {
          "author": {
            "name": "soulitzer",
            "email": "soulitzer@gmail.com",
            "date": "2023-01-23T22:36:04Z"
          },
          "committer": {
            "name": "soulitzer",
            "email": "soulitzer@gmail.com",
            "date": "2023-01-23T22:36:04Z"
          },
          "message": "Revert \"Create autograd Function for aot_autograd backward only when needed (#92688)\"\n\nThis reverts commit a3efa9d740b297f69eaa0d289aba8410de3a52cc.\n\n[ghstack-poisoned]",
          "tree": {
            "sha": "819208777d41def76403641d2b553eea07d42ef2",
            "url": "https://api.github.com/repos/pytorch/pytorch/git/trees/819208777d41def76403641d2b553eea07d42ef2"
          },
          "url": "https://api.github.com/repos/pytorch/pytorch/git/commits/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
          "comment_count": 0,
          "verification": {
            "verified": false,
            "reason": "unsigned",
            "signature": null,
            "payload": null
          }
        },
        "url": "https://api.github.com/repos/pytorch/pytorch/commits/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
        "html_url": "https://github.com/pytorch/pytorch/commit/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
        "comments_url": "https://api.github.com/repos/pytorch/pytorch/commits/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6/comments",
        "author": {
          "login": "soulitzer",
          "id": 13428986,
          "node_id": "MDQ6VXNlcjEzNDI4OTg2",
          "avatar_url": "https://avatars.githubusercontent.com/u/13428986?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/soulitzer",
          "html_url": "https://github.com/soulitzer",
          "followers_url": "https://api.github.com/users/soulitzer/followers",
          "following_url": "https://api.github.com/users/soulitzer/following{/other_user}",
          "gists_url": "https://api.github.com/users/soulitzer/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/soulitzer/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/soulitzer/subscriptions",
          "organizations_url": "https://api.github.com/users/soulitzer/orgs",
          "repos_url": "https://api.github.com/users/soulitzer/repos",
          "events_url": "https://api.github.com/users/soulitzer/events{/privacy}",
          "received_events_url": "https://api.github.com/users/soulitzer/received_events",
          "type": "User",
          "site_admin": false
        },
        "committer": {
          "login": "soulitzer",
          "id": 13428986,
          "node_id": "MDQ6VXNlcjEzNDI4OTg2",
          "avatar_url": "https://avatars.githubusercontent.com/u/13428986?v=4",
          "gravatar_id": "",
          "url": "https://api.github.com/users/soulitzer",
          "html_url": "https://github.com/soulitzer",
          "followers_url": "https://api.github.com/users/soulitzer/followers",
          "following_url": "https://api.github.com/users/soulitzer/following{/other_user}",
          "gists_url": "https://api.github.com/users/soulitzer/gists{/gist_id}",
          "starred_url": "https://api.github.com/users/soulitzer/starred{/owner}{/repo}",
          "subscriptions_url": "https://api.github.com/users/soulitzer/subscriptions",
          "organizations_url": "https://api.github.com/users/soulitzer/orgs",
          "repos_url": "https://api.github.com/users/soulitzer/repos",
          "events_url": "https://api.github.com/users/soulitzer/events{/privacy}",
          "received_events_url": "https://api.github.com/users/soulitzer/received_events",
          "type": "User",
          "site_admin": false
        },
        "parents": [
          {
            "sha": "8972a9fe6aa8be8f8035c83094ed371973bfbe73",
            "url": "https://api.github.com/repos/pytorch/pytorch/commits/8972a9fe6aa8be8f8035c83094ed371973bfbe73",
            "html_url": "https://github.com/pytorch/pytorch/commit/8972a9fe6aa8be8f8035c83094ed371973bfbe73"
          }
        ]
      }
    ],
    "files": [
      {
        "sha": "1f4a46487506e08bb5f5cf4ccd4287bc3d2819e1",
        "filename": "test/dynamo/test_aot_autograd.py",
        "status": "modified",
        "additions": 0,
        "deletions": 59,
        "changes": 59,
        "blob_url": "https://github.com/pytorch/pytorch/blob/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6/test%2Fdynamo%2Ftest_aot_autograd.py",
        "raw_url": "https://github.com/pytorch/pytorch/raw/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6/test%2Fdynamo%2Ftest_aot_autograd.py",
        "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/test%2Fdynamo%2Ftest_aot_autograd.py?ref=030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
        "patch": "@@ -332,65 +332,6 @@ def guard_fail_fn(failure):\n         self.assertEqual(cc.frame_count, 1)\n         self.assertTrue(failure_reason is None)\n \n-    def test_double_backward_errors(self):\n-        # Remove this test after we get double backward to actually work\n-        for grad_output in (torch.tensor(1.0, requires_grad=True), None):\n-            # See @once_differentiable docs for why there are two different errors\n-            x = torch.tensor(1.0, requires_grad=True)\n-            err = \"torch.compile with aot_autograd does not currently support double backward\"\n-\n-            # The following cases should be equivalent:\n-\n-            # (1) double backward entirely inside compiled function\n-            def f1(x):\n-                y = x.sin().exp()\n-                (gx,) = torch.autograd.grad(\n-                    y, x, create_graph=True, grad_outputs=grad_output\n-                )\n-                gx.backward()\n-                return gx\n-\n-            compiled_f1 = torch.compile(backend=\"aot_eager\")(f1)\n-            f1(x)\n-            with self.assertRaisesRegex(RuntimeError, err):\n-                compiled_f1(x)\n-\n-            # (2) the second half of double backward outside compiled function\n-            def f2(x):\n-                y = x.sin().exp()\n-                (gx,) = torch.autograd.grad(\n-                    y, x, create_graph=True, grad_outputs=grad_output\n-                )\n-                return gx\n-\n-            compiled_f2 = torch.compile(backend=\"aot_eager\")(f2)\n-            gx = compiled_f2(x)\n-            with self.assertRaisesRegex(RuntimeError, err):\n-                gx.backward()\n-\n-            # (3) double backward entirely outside compiled function\n-            def f3(x):\n-                y = x.sin().exp()\n-                return y\n-\n-            compiled_f3 = torch.compile(backend=\"aot_eager\")(f3)\n-            y = compiled_f3(x)\n-            (gx,) = torch.autograd.grad(\n-                y, x, create_graph=True, grad_outputs=grad_output\n-            )\n-            with self.assertRaisesRegex(RuntimeError, err):\n-                gx.backward()\n-\n-        # create_graph=False\n-        def f4(x):\n-            y = x.sin().exp()\n-            return y\n-\n-        compiled_f4 = torch.compile(backend=\"aot_eager\")(f4)\n-        x = torch.tensor(1.0, requires_grad=True)\n-        y = compiled_f4(x)\n-        (gx,) = torch.autograd.grad(y, x, create_graph=False, grad_outputs=grad_output)\n-\n     @patch(\"torch._functorch.config.debug_assert\", True)\n     def test_arg_dupe_via_dynamo_recompiles(self):\n         class F(torch.nn.Module):"
      },
      {
        "sha": "2769b284b7b3c4fbbc15e447c75829c6c64a9edb",
        "filename": "torch/_functorch/aot_autograd.py",
        "status": "modified",
        "additions": 15,
        "deletions": 37,
        "changes": 52,
        "blob_url": "https://github.com/pytorch/pytorch/blob/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6/torch%2F_functorch%2Faot_autograd.py",
        "raw_url": "https://github.com/pytorch/pytorch/raw/030a6d3fe98e46c82cdbae9b93a72ceab4febfd6/torch%2F_functorch%2Faot_autograd.py",
        "contents_url": "https://api.github.com/repos/pytorch/pytorch/contents/torch%2F_functorch%2Faot_autograd.py?ref=030a6d3fe98e46c82cdbae9b93a72ceab4febfd6",
        "patch": "@@ -1858,44 +1858,22 @@ def backward(ctx, *flat_args):\n                 list(ctx.symints) + list(ctx.saved_tensors) + list(contiguous_args)\n             )\n             del contiguous_args\n+            if CompiledFunction.compiled_bw is None:\n+                # TODO - pass in fake tensors ?\n+                context = disable_autocast_manager if disable_amp else nullcontext\n+                with context(), track_graph_compiling(aot_config, \"backward\"):\n+                    CompiledFunction.compiled_bw = aot_config.bw_compiler(\n+                        bw_module, all_args\n+                    )\n \n-            def call_compiled_backward(all_args):\n-                all_args_list = list(all_args)\n-                if CompiledFunction.compiled_bw is None:\n-                    # TODO - pass in fake tensors ?\n-                    context = disable_autocast_manager if disable_amp else nullcontext\n-                    with context(), track_graph_compiling(aot_config, \"backward\"):\n-                        CompiledFunction.compiled_bw = aot_config.bw_compiler(\n-                            bw_module, all_args_list\n-                        )\n-\n-                ctx.maybe_clear_saved_tensors()\n-                out = call_func_with_args(\n-                    CompiledFunction.compiled_bw,\n-                    all_args_list,\n-                    steal_args=True,\n-                    disable_amp=disable_amp,\n-                )\n-                return tuple(out)\n-\n-            if torch.is_grad_enabled() and any(t.requires_grad for t in all_args if isinstance(t, torch.Tensor)):\n-                # If backward pass was run with create_graph=True, ensure that the graph is\n-                # properly connected, but errors when the user performs double backward.\n-                # See comment for why once_differentiable is not sufficient:\n-                # https://github.com/pytorch/pytorch/pull/92348/files#r1072962107\n-                class CompiledFunctionBackward(torch.autograd.Function):\n-                    @staticmethod\n-                    def forward(ctx, *all_args):\n-                        return call_compiled_backward(all_args)\n-\n-                    @staticmethod\n-                    def backward(ctx, *args):\n-                        raise RuntimeError(\"torch.compile with aot_autograd does not currently support double backward\")\n-\n-                out = CompiledFunctionBackward.apply(*all_args)\n-            else:\n-                out = call_compiled_backward(all_args)\n-            return out\n+            ctx.maybe_clear_saved_tensors()\n+            out = call_func_with_args(\n+                CompiledFunction.compiled_bw,\n+                all_args,\n+                steal_args=True,\n+                disable_amp=disable_amp,\n+            )\n+            return tuple(out)\n \n     @wraps(CompiledFunction.apply)\n     def compiled_function(*args):"
      }
    ]
  }
}
